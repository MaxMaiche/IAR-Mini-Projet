{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ad0e1a3",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[easypip] Installing bbrl_utils\n"
     ]
    }
   ],
   "source": [
    "# Prepare the environment\n",
    "try:\n",
    "    from easypip import easyimport\n",
    "except ModuleNotFoundError:\n",
    "    from subprocess import run\n",
    "\n",
    "    assert (\n",
    "        run([\"pip\", \"install\", \"easypip\"]).returncode == 0\n",
    "    ), \"Could not install easypip\"\n",
    "    from easypip import easyimport\n",
    "\n",
    "easyimport(\"swig\")\n",
    "easyimport(\"bbrl_utils\").setup(maze_mdp=True)\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import bbrl_gymnasium  # noqa: F401\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from bbrl.agents import Agent, Agents, TemporalAgent\n",
    "from bbrl_utils.algorithms import EpochBasedAlgo\n",
    "from bbrl_utils.nn import build_mlp, setup_optimizer, soft_update_params\n",
    "from bbrl_utils.notebook import setup_tensorboard\n",
    "from bbrl.visu.plot_policies import plot_policy\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1732edc6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class ContinuousQAgent(Agent):\n",
    "    def __init__(self, state_dim, hidden_layers, action_dim):\n",
    "        super().__init__()\n",
    "        self.is_q_function = True\n",
    "        self.model = build_mlp(\n",
    "            [state_dim + action_dim] + list(hidden_layers) + [1], activation=nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, t):\n",
    "        # Get the current state $s_t$ and the chosen action $a_t$\n",
    "        obs = self.get((\"env/env_obs\", t))  # shape B x D_{obs}\n",
    "        action = self.get((\"action\", t))  # shape B x D_{action}\n",
    "\n",
    "        # Compute the Q-value(s_t, a_t)\n",
    "        obs_act = torch.cat((obs, action), dim=1)  # shape B x (D_{obs} + D_{action})\n",
    "        # Get the q-value (and remove the last dimension since it is a scalar)\n",
    "        q_value = self.model(obs_act).squeeze(-1)\n",
    "        self.set((f\"{self.prefix}q_value\", t), q_value)\n",
    "\n",
    "    def predict_value(self, obs, action):\n",
    "        obs_act = torch.cat((obs, action), dim=0)\n",
    "        q_value = self.model(obs_act)\n",
    "        return q_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97fe4ed3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class ContinuousDeterministicActor(Agent):\n",
    "    def __init__(self, state_dim, hidden_layers, action_dim):\n",
    "        super().__init__()\n",
    "        layers = [state_dim] + list(hidden_layers) + [action_dim]\n",
    "        self.model = build_mlp(\n",
    "            layers, activation=nn.ReLU(), output_activation=nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, t, **kwargs):\n",
    "        obs = self.get((\"env/env_obs\", t))\n",
    "        action = self.model(obs)\n",
    "        self.set((\"action\", t), action)\n",
    "\n",
    "    def predict_action(self, obs, stochastic):\n",
    "        assert (\n",
    "            not stochastic\n",
    "        ), \"ContinuousDeterministicActor cannot provide stochastic predictions\"\n",
    "        return self.model(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d88bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b1ada13",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class AddGaussianNoise(Agent):\n",
    "    def __init__(self, sigma):\n",
    "        super().__init__()\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, t, **kwargs):\n",
    "        act = self.get((\"action\", t))\n",
    "        dist = Normal(act, self.sigma)\n",
    "        action = dist.sample()\n",
    "        self.set((\"action\", t), action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249794ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddOUNoise(Agent):\n",
    "    \"\"\"\n",
    "    Ornstein Uhlenbeck process noise for actions as suggested by DDPG paper\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, std_dev, theta=0.15, dt=1e-2):\n",
    "        self.theta = theta\n",
    "        self.std_dev = std_dev\n",
    "        self.dt = dt\n",
    "        self.x_prev = 0\n",
    "\n",
    "    def forward(self, t, **kwargs):\n",
    "        act = self.get((\"action\", t))\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (act - self.x_prev) * self.dt\n",
    "            + self.std_dev * math.sqrt(self.dt) * torch.randn(act.shape)\n",
    "        )\n",
    "        self.x_prev = x\n",
    "        self.set((\"action\", t), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2da720",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def compute_actor_loss(q_values):\n",
    "    \"\"\"Returns the actor loss\n",
    "\n",
    "    :param q_values: The q-values (shape 2xB)\n",
    "    :return: A scalar (the loss)\n",
    "    \"\"\"\n",
    "    return -q_values[0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "943cade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_critic_loss_td3(cfg, reward, must_bootstrap, q_values, target_q_values_1, target_q_values_2):\n",
    "    \"\"\"\n",
    "    Compute the TD3 critic loss from a sample of transitions\n",
    "    \"\"\"\n",
    "    target = reward[1] + cfg.algorithm.discount_factor * torch.min(target_q_values_1[1], target_q_values_2[1]) * must_bootstrap[1].int()\n",
    "    mse = nn.MSELoss()\n",
    "    critic_loss = mse(q_values[0], target)\n",
    "    \n",
    "    return critic_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a96a6a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TD3(EpochBasedAlgo):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__(cfg)\n",
    "\n",
    "        # Define the agents and optimizers for TD3\n",
    "\n",
    "        # we create the critic and the actor, but also an exploration agent to\n",
    "        # add noise and a target critic. The version below does not use a target\n",
    "        # actor as it proved hard to tune, but such a target actor is used in\n",
    "        # the original paper.\n",
    "\n",
    "        obs_size, act_size = self.train_env.get_obs_and_actions_sizes()\n",
    "        self.critic_1 = ContinuousQAgent(\n",
    "            obs_size, cfg.algorithm.architecture.critic_hidden_size, act_size\n",
    "        ).with_prefix(\"critic_1/\")\n",
    "        \n",
    "        self.critic_2 = ContinuousQAgent(\n",
    "            obs_size, cfg.algorithm.architecture.critic_hidden_size, act_size\n",
    "        ).with_prefix(\"critic_2/\")\n",
    "        \n",
    "        self.target_critic_1 = copy.deepcopy(self.critic_1).with_prefix(\"target-critic_1/\")\n",
    "        self.target_critic_2 = copy.deepcopy(self.critic_2).with_prefix(\"target-critic_2/\")\n",
    "\n",
    "    \n",
    "        self.actor = ContinuousDeterministicActor(\n",
    "            obs_size, cfg.algorithm.architecture.actor_hidden_size, act_size\n",
    "        )\n",
    "\n",
    "        # As an alternative, you can use `AddOUNoise`\n",
    "        noise_agent = AddGaussianNoise(cfg.algorithm.action_noise)\n",
    "\n",
    "        self.train_policy = Agents(self.actor, noise_agent)\n",
    "        self.eval_policy = self.actor\n",
    "\n",
    "        # Define agents over time\n",
    "        self.t_actor = TemporalAgent(self.actor)\n",
    "        self.t_critic_1 = TemporalAgent(self.critic_1)\n",
    "        self.t_critic_2 = TemporalAgent(self.critic_2)\n",
    "        self.t_target_critic_1 = TemporalAgent(self.target_critic_1)\n",
    "        self.t_target_critic_2 = TemporalAgent(self.target_critic_2)\n",
    "\n",
    "        # Configure the optimizer\n",
    "        self.actor_optimizer = setup_optimizer(cfg.actor_optimizer, self.actor)\n",
    "        self.critic_optimizer_1 = setup_optimizer(cfg.critic_optimizer, self.critic_1)\n",
    "        self.critic_optimizer_2 = setup_optimizer(cfg.critic_optimizer, self.critic_2)\n",
    "\n",
    "\n",
    "def run_td3(td3: TD3):\n",
    "    for rb in td3.iter_replay_buffers():\n",
    "        rb_workspace = rb.get_shuffled(td3.cfg.algorithm.batch_size)\n",
    "\n",
    "        terminated, reward = rb_workspace[\"env/terminated\", \"env/reward\"]\n",
    "\n",
    "        # Determines whether values of the critic should be propagated\n",
    "        # True if the episode reached a time limit or if the task was not done\n",
    "        # See https://github.com/osigaud/bbrl/blob/master/docs/time_limits.md\n",
    "        must_bootstrap = ~terminated\n",
    "\n",
    "        # Random chooser\n",
    "        do1 = False\n",
    "        do2 = False\n",
    "        rdm = torch.randint(0, 3, (1,))\n",
    "        if rdm == 0:\n",
    "            do1 = True\n",
    "            do2 = True\n",
    "        elif rdm == 1:\n",
    "            do1 = True\n",
    "        elif rdm == 2:\n",
    "            do2 = True\n",
    "        \n",
    "        # Critic update\n",
    "        # compute q_values: at t, we have Q(s,a) from the (s,a) in the RB\n",
    "        \n",
    "        td3.t_critic_1(rb_workspace, t=0, n_steps=1)\n",
    "        td3.t_critic_2(rb_workspace, t=0, n_steps=1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # replace the action at t+1 in the RB with \\pi(s_{t+1}), to compute\n",
    "            # Q(s_{t+1}, \\pi(s_{t+1}) below\n",
    "            td3.t_actor(rb_workspace, t=1, n_steps=1)\n",
    "            # compute q_values: at t+1 we have Q(s_{t+1}, \\pi(s_{t+1})\n",
    "            td3.t_target_critic_1(rb_workspace, t=1, n_steps=1)\n",
    "            td3.t_target_critic_2(rb_workspace, t=1, n_steps=1)\n",
    "\n",
    "        # finally q_values contains the above collection at t=0 and t=1\n",
    "        q_values_1, post_q_values_1 = rb_workspace[\n",
    "            \"critic_1/q_value\", \"target-critic_1/q_value\"\n",
    "        ]\n",
    "        \n",
    "        q_values_2, post_q_values_2 = rb_workspace[\n",
    "            \"critic_2/q_value\", \"target-critic_2/q_value\"\n",
    "        ]\n",
    "\n",
    "        # Compute critic loss\n",
    "        if do1:\n",
    "            critic_loss_1 = compute_critic_loss_td3(\n",
    "                td3.cfg, reward, must_bootstrap, q_values_1, post_q_values_1, post_q_values_2\n",
    "            )\n",
    "        if do2:\n",
    "            critic_loss_2 = compute_critic_loss_td3(\n",
    "                td3.cfg, reward, must_bootstrap, q_values_2, post_q_values_2, post_q_values_1\n",
    "            )\n",
    "        if do1:\n",
    "            td3.logger.add_log(\"critic_loss_1\", critic_loss_1, td3.nb_steps)\n",
    "        if do2:    \n",
    "            td3.logger.add_log(\"critic_loss_2\", critic_loss_2, td3.nb_steps)\n",
    "        \n",
    "        \n",
    "        if do1:\n",
    "            td3.critic_optimizer_1.zero_grad()\n",
    "            critic_loss_1.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                td3.critic_1.parameters(), td3.cfg.algorithm.max_grad_norm\n",
    "            )\n",
    "            td3.critic_optimizer_1.step()\n",
    "        if do2:\n",
    "            td3.critic_optimizer_2.zero_grad()\n",
    "            critic_loss_2.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(\n",
    "                td3.critic_2.parameters(), td3.cfg.algorithm.max_grad_norm\n",
    "            )\n",
    "            td3.critic_optimizer_2.step()\n",
    "\n",
    "        # Actor update\n",
    "\n",
    "        # Now we determine the actions the current policy would take in the states from the RB\n",
    "        td3.t_actor(rb_workspace, t=0, n_steps=1)\n",
    "\n",
    "        if do1: \n",
    "            # We determine the Q values resulting from actions of the current policy\n",
    "            td3.t_critic_1(rb_workspace, t=0, n_steps=1)\n",
    "        if do2:\n",
    "            td3.t_critic_2(rb_workspace, t=0, n_steps=1)\n",
    "                \n",
    "        \n",
    "\n",
    "        # and we back-propagate the corresponding loss to maximize the Q values\n",
    "        q_values = rb_workspace[\"critic_1/q_value\"]\n",
    "        actor_loss = compute_actor_loss(q_values)\n",
    "\n",
    "        td3.logger.add_log(\"actor_loss\", actor_loss, td3.nb_steps)\n",
    "\n",
    "        # if -25 < actor_loss < 0 and nb_steps > 2e5:\n",
    "        td3.actor_optimizer.zero_grad()\n",
    "        actor_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            td3.actor.parameters(), td3.cfg.algorithm.max_grad_norm\n",
    "        )\n",
    "        td3.actor_optimizer.step()\n",
    "\n",
    "        # Soft update of target q function\n",
    "        soft_update_params(\n",
    "            td3.critic_1, td3.target_critic_1, td3.cfg.algorithm.tau_target\n",
    "        )\n",
    "\n",
    "        if td3.evaluate():\n",
    "            if td3.cfg.plot_agents:\n",
    "                plot_policy(\n",
    "                    td3.actor,\n",
    "                    td3.eval_env,\n",
    "                    td3.best_reward,\n",
    "                    str(td3.base_dir / \"plots\"),\n",
    "                    td3.cfg.gym_env.env_name,\n",
    "                    stochastic=False,\n",
    "                )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5edab124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23440), started 4 days, 23:31:17 ago. (Use '!kill 23440' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-48e9933392026958\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-48e9933392026958\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setup_tensorboard(\"./outputs/tblogs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81372d39",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555eab04a5154850bcb95570f0f8199f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video of best agent recorded in outputs\\LunarLanderContinuous-v2\\td3-S1_20241009-221109\\best_agent.mp4\n",
      "Moviepy - Building video C:\\Users\\Max\\Desktop\\code\\M2\\IAR\\IAR-Mini-Projet\\outputs\\LunarLanderContinuous-v2\\td3-S1_20241009-221109\\best_agent.mp4.\n",
      "Moviepy - Writing video C:\\Users\\Max\\Desktop\\code\\M2\\IAR\\IAR-Mini-Projet\\outputs\\LunarLanderContinuous-v2\\td3-S1_20241009-221109\\best_agent.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready C:\\Users\\Max\\Desktop\\code\\M2\\IAR\\IAR-Mini-Projet\\outputs\\LunarLanderContinuous-v2\\td3-S1_20241009-221109\\best_agent.mp4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div align=middle><video src='data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAOmttZGF0AAACoQYF//+d3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE1OSAtIEguMjY0L01QRUctNCBBVkMgY29kZWMgLSBDb3B5bGVmdCAyMDAzLTIwMTkgLSBodHRwOi8vd3d3LnZpZGVvbGFuLm9yZy94MjY0Lmh0bWwgLSBvcHRpb25zOiBjYWJhYz0xIHJlZj0zIGRlYmxvY2s9MTowOjAgYW5hbHlzZT0weDM6MHgxMTMgbWU9aGV4IHN1Ym1lPTcgcHN5PTEgcHN5X3JkPTEuMDA6MC4wMCBtaXhlZF9yZWY9MSBtZV9yYW5nZT0xNiBjaHJvbWFfbWU9MSB0cmVsbGlzPTEgOHg4ZGN0PTEgY3FtPTAgZGVhZHpvbmU9MjEsMTEgZmFzdF9wc2tpcD0xIGNocm9tYV9xcF9vZmZzZXQ9LTIgdGhyZWFkcz0xMiBsb29rYWhlYWRfdGhyZWFkcz0yIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVybGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9weXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0wIHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVmcmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAAAXTZYiEADP//vbsvgU2FMhQlxEsxdpKcD4qpICAdzTav25isNWAEpOKvSvlcPTWCu8mVywdxT0x/atZ+HIkExagdhKzqQ/Ve3WwFbu089HA3gexM1u6G1/SUmUc9rONMV9Km+ZohekhhNjxPUc7nJ2FxGeS1w6MCHUD7wFMXtL+KXMjnfTndkd7aeAGuGWG/Z1Pps4XC1uea523ReHrKwkagrGnKb22EQ7xWnr3r5X2YHDqjdj8Yx2i2a8MM/AAAAMAAAMB736xNrqI7kgPn/fcjR1vRFsAAPAGRNEDnC9jCjgEVHgNocA2CDFsBcy1Ke9WaWiK/lH1NEVCJxqphMhN08mz+/DrmntmI6hM5YJFRx5R8JC3Jll45OeNxU/QKoHLn6hyqqFc5oJ/x1CiHw6XHdKfta7j6hyWkJHlF5Hu7tPUkLDVB/MG2WnveujfHHJHcc3xh0SkEUe0ft8guZR7AFf6UK5ElzbLEBeu1u9TTmj08+LoQx3W1/jsD5maQUWFyAdQ3C+TBOpHYc5f1UrE9NBOfIpz9cWL4KjQjaKM5dnGoV6q4XAwdnq+5vfuNtcdqoY9GshcnSm6nG0gzBuJIMDyT/86T2XQmDoI97sXI9Pb7Ti/dtbxSQUNScJfbLPiudr0fgRGZAhh3aIPVdIG2ZWV+JeE6PS+b/xdQcyiSYVsklITkClpoFLrJkxqNoOaUt3VOBVzYBXb98pdxErJ6IEU0rSPWY+Gbb8G7z8H/scFYLuTq2toMoqPhabkOvXfC7bikHrpOdhMQ16TU65xzKeqCrY5NzKw+PukV3y8AjrmXRP/4KeucpIFvE0vm2y9tCfTvq++OgY1xASj7jJll1qk6tjzPB8BhTc7yP+EKdQR88P4Jk3LsdiyRMozrT0KeCV26n/5JUJGYNqMUw+9veih1idiW33vF5YG9RAUvHRovd0Jcvzzms5enph/Ny82bohTPvx3zxkoIFtpd1Wqr7qADi1D/Ne39rj7z+NpwR5h8QmvSEOiXS+shVAIMuN6DtCcWlwJVPDJ7gXMzaE+MpWeYkqtuW/SE97785a5s93Ng9hCidqz/6H+66Set5N5HrZp/EMZnA3U2AgUe6Vx9+558tdtFZv4lxEfMOjmerhL1OfVX+ZodW03rWARGwVp1VpBrGcqKA8RJMrReAk/0XonnRYEKmVQ6518YmXC0zGMYTzJ0uGxryRk1FGHGMmVt5QYAboHjd+Oxl13wDWbdGjLvyMu+aK3okjW6L+5diAq6WiPeKZvQNMB1MbuJ5mqynxOG20wY8K8RmDe/ULb3hQ6s7qC9UARw+T/PduxKmChbxrYyfa+k1YrtejJ05mr8yNvyRqNUWCc2bQIBI7g6RCgd+0g0wRhTJZfE8H6S2r72jWH0c+q5dc4yu7jQXq7ahGRYO0yEpzZRJClL3ijb5kqhyUXilLU2A7FoFIlvfHgItxv6/q7bRFe61W5VwVeKE536DDKY+7oDWiOFwjmYL3rB/Lglh8ba3YeR0MueTVrkNS1e3HwVLc4avEqHHxSt+CRf91KqmzkLmr442Mj9cA9gTjKVXiNm0iA8DTDuAOeV2gLO58GTbihWGN1ogndFDFuycu+aZTZ9g0WRHF8iuoFyd2X35MSX9W774DT6bnyLgyS+f9Pl7+7q7Z5mxZQGMjQnw/fgc1EzeaVmVR1RpyYAAAIJlX6dQArhdaYQlEECRDV46oG4I3dHkgKfnctxrAUlPVvtrRla/zvpHfeQkoX5ix4rR4nWsmRQ6Pb/pM40WkrMP54DQBu/lHADtHR73E4nPXsIsy5vp3fLTdVOzsAy6BCjC6USPs5EU4iEddvHUny7KcKntL5/Pwt/WMBUVJb4bLfryatnyP3kC0FXHFuNSzeNMAHbpY/lx/NRq22hPzBvMcMwTNyT8z0XY0ts6WReeUoqsqYVd3VeE0xHkm1gGOIf5UF2ZJmJv5Si4zm2ShctrqAAAh+apAAAAMAANmBAAAAvkGaJGxDP/6eKtJj1BHcxAAx8pYE0xVMcHcRK1h+Ie4Gm1l6bU9I2FP8/hgAAAMAAfx33a1KpIOjjf8uWjt9N5/abgPsxVScxi1l3sq0pl/UTyGeMlAmdOYCEC988ny7vaBfzyUNXyb6iVngn8ZDDSnnRIyP/NE+Wfjd5nGCj74UOuRUGS/dmIEBZzFxkLZE8hmQ95rKHpOQtAjQRiAlyFr2bW6OCS8ZNSAkMFVHbqSAUDteL3xAz8Lggqyf5dwAAAA8QZ5CeIR/D4PQUs8FY2R24rmAESG228lNQyW881cTsuxBjYyJzuTy4aM67v/7jGky4IluOWYAph8pgNmBAAAAKgGeYXRH/xUpESD8D061CHik2lQAHexN8V9q0mtwgQSrbOmhWeS1JiB6QAAAACQBnmNqR/8VGlBZ4ehYAGcarOCsLIAeJzLaZ5ncH4AD/MeCRZUAAABwQZpoSahBaJlMCGf//p4qaLFTM4D3dprH437L7holo3voEAAAAwANW77talUj+qWOcE0Uuu6nFByztunJ/HFr7ptKS6MCHldBuHABYB+XtPU4f8vHv/YkficxmJuXiX3LPpAOErs5UHC5ezEHQQAEPQAAAC5BnoZFESwj/w97AUO9t2iFPqLqADYgRHIN2mBBZMUp1SWt89scYbvwAhOYyAFTAAAAJgGepXRH/xUplFV9XeEtDjmoAGliO3dA8QLVNmNUqYtWgHLjiAm5AAAAKQGep2pH/xUa6i69g5Fnwy7moAGmfBVlulVwt2Msp2BVEQh3/LYaoAFTAAAAsEGarEmoQWyZTAhn//6eLdjn8a0LPgBcL831AQP6+v1GAyTr1KoNCnpxtPLJggUYo7gBACAYOiMThpuvJuHCCTGFlTpPP9JdsuFqLH5pkWQbYu40qUyp/SRmVg+quo2YPSzYvkLmpc/Lab/cvnVcuzT8KatZ/QIc5wcT9ppVA6aQvIryOTsmbUOuzYpMZgIYXa/8CfTcVj9wTPY1aTzE1h84t/Qz8a6vISuoqgC/4GfAAAAATkGeykUVLCP/D3LIqZ0OIqxPiAH9TMcowam+zgNjRoHNHUJTjoJ7f5jNGMJK/rEPwJ74CwhE1tARYVQ+k7b/QRarsNnWpcHicvDvHBcBxwAAADsBnul0R/8VKZSIHO5AAWHsVIjidua2BxNzZ/oBXuIgdRdzA9fIAmEBt8V3Wz0qXschmXvaAAAzBIC7gAAAADcBnutqR/8U/d9K8rryktsAOH15lMO8GC2n42qbKzh4/XA7c8PzQD91PaFkZpqqj/yYwKfJQAGLAAAAWUGa8EmoQWyZTAhn//6eHRec050AGuon8C97n0M/gqyHZwt4rXP4rQFr8bLAM0FAAAAQkT3/vu1qVb20LsaVVCQpI0oIOvIclpLa12E4MM05nbGgO5HElFBhAAAAOkGfDkUVLCP/DKcUQAAjp+IPzs9+JYV2fIXcCsNneVrzXSy96P97LnnsYAt4RJhTIouHu4cEdn4ACkkAAAA2AZ8tdEf/EVHbXuqeAEOIzM/25RIUjk27a/hMM98KyJT/LMqirBqUAcQj/wpN/mFaAf9BayRhAAAAKwGfL2pH/xFl7KIzZKigAZ8/GnWCsdWPO6BunqAT6o8pchzUZX/d2IIkccAAAAA5QZs0SahBbJlMCGf//p4dUJ/2SACDh970DLg3W2OKSAZi3WQC/5fuNpuhtpQILNoAAVrFx0KowCpgAAAAMkGfUkUVLCP/DgEbb/59wBQVVF7YummH/vxNoIeAAC4AU/meO3NRQAfEezk+j1jsIMqBAAAAKQGfcXRH/xF19lmz4AVpG//N1KmbrnzIoAcQV9ohLhOLHuPceVNaZLIuAAAAIgGfc2pH/xMoNs07levPaNfuJgB8T9HP4EgCT9tpX5H0o44AAABVQZt4SahBbJlMCGf//p4cl0MafQBDvqULBYQCyYa2cAAAB9sUsDYAEx7nImtIwlZf7vu2qZhVEHyDmYICIO4al/xCIkD8n5kPYy7YjbL/Jm1EOf3BvQAAADtBn5ZFFSwj/wvy/EBPSpOt9sxekPNIjXBJKqFdtstnctpWSTmADGeYhxW2oGMydDXXUwK6fT5yLwAFfAAAAD4Bn7V0R/8RdR6qQAGoLs8V6dCMrmNHXBl0QKF20TXspBk8gkx4URFMn2DMwXFwBWFT7cv4brXGWIOOtFQBVwAAADUBn7dqR/8RXlKBRirrAFb626RosaixaF5SC87B7ZvdT2vEfGXAFZ2B27C/SeRFgJqCV9ADUwAAADNBm7xJqEFsmUwIZ//+nh1c93gSYf++IAPLZgD4FN7q69E0wLjFKyEAAqi8go8mmgQj7aAAAAAmQZ/aRRUsI/8MnchyiLxOG0UAAdseQPdLO+HmCpxGqOSLayiADbkAAAAoAZ/5dEf/EZlsVZMM3WAHSDsm+fUvAeVSDsYoAA74dCwsTAdTh6EBgQAAACYBn/tqR/8QkR2w+dqqgoARpH9nq511n1wADzRB6Inm4zG3mNg+YQAAACxBm+BJqEFsmUwIZ//+nhwYm+AAmdAlYYaoYPGRlViBNHWEAAIqlkp8GkbaaQAAACBBnh5FFSwj/w0xAloTGUeUABFjV6QbvSkMbo0mJAADZgAAABkBnj10R/8TBEtwQqgABBTJD5B9gpjOQAVsAAAAGAGeP2pH/xMoSfgAAchmfiyGXb92ZcWD5wAAACdBmiRJqEFsmUwIZ//+nhwwJxgBYbMz9sXaKBtQAAdzhPIgT+C1CYMAAAAmQZ5CRRUsI/8ODAarH8nABYabgw6VKgAEF6eXGJYxVNnC3c0AAakAAAAwAZ5hdEf/EwRETMACw7kMbsMfgb9CJC2q1b2g39n8FchAACMpdqAFbj53J4PvNwQcAAAAIwGeY2pH/xMoR86AGi7TH28RojJgACxXnD2OVq3zn6ev3wQdAAAAS0GaaEmoQWyZTAhn//6eHAeVydM42HtACmP35LIQAAADADP483vdtUy8wjoEolLizynjUI6/B3Ltxg2etAwYA7fRWQbC9ZdT7T7omQAAACZBnoZFFSwj/w4MBT6N4OAATm8ueC2FRtLJpLTZcSkGb+B5qwAJOQAAACwBnqV0R/8TBD1DnGAHKoEgXcoi92vlVjh9mOQl8ACSgASY6Y8wYrNvfAChgQAAACgBnqdqR/8TKDrfPNABtatXEFT+59M2XjGABsGnDhBflZp5IlBAAPSAAAAAR0GarEmoQWyZTAhn//6eHDK1c6IAVfGr4/Gs72OqjpwRelBh+upgAAADAIbFl6jva1KrPo6X+QyZhYvbqa8A0mmjkn3c9uEXAAAAIUGeykUVLCP/Dgv8sfmjFfgALdzKUayG/K5l36/E4gACtwAAABkBnul0R/8TBEpwAC7dx+ezWlq6OUQQmAi4AAAAFwGe62pH/xMoSfgAF3wLkNrMFW37vNBwAAAAGUGa8EmoQWyZTAhn//6eHDALQEwAAAMAAu8AAAAaQZ8ORRUsI/8ODAaPwABgepjZR3FRlBcYIOEAAAAjAZ8tdEf/EwRFfQQBXisBYCYiuWmAldrwAAbmcmnSS8wotuEAAAAeAZ8vakf/EyhHQOACUoeVqwqEFgAB/GYdNeyJPZP8AAAAF0GbNEmoQWyZTAhn//6eEAAAAwAAAwM+AAAAGkGfUkUVLCP/DgwGj8AAYHqY2UdxUZQXGCDhAAAAJQGfcXRH/xMER/wIAM+fdxQatJ3aJXMN26UbAABZOudOhLwj+v8AAAAVAZ9zakf/EyhJ+AAByGZbjhAii2aNAAAAF0GbeEmoQWyZTAhn//6eEAAAAwAAAwM/AAAAGkGflkUVLCP/DgwGj8AAYHqY2UdxUZQXGCDgAAAAFQGftXRH/xMESnAAA46hgWmoYpxemQAAABUBn7dqR/8TKEn4AAHIZluOECKLZo0AAAAXQZu8SahBbJlMCGf//p4QAAADAAADAz4AAAAmQZ/aRRUsI/8ODAYb8gJKDvP31Ja1fHtEAAHQ6pblHAfGaGLgg4EAAAAXAZ/5dEf/EwRBCoWAABYcjnI9pN9gg4AAAAAjAZ/7akf/EygVz2o8DgDiPomlF4MHYhDTAAAtdN/rDvedyg8AAAAoQZvgSahBbJlMCGf//p4ZMjX8FkMUANmPwS81dFAASQGsHgAAAwABQQAAAB1Bnh5FFSwj/w4MA/m3P8hgAAPNxUI5cF6LUHUZ8AAAABMBnj10R/8TBEpwAACcH7STjGycAAAAIgGeP2pH/xMoR3dgDlAGrOe3qEGWKLjVd4AACW9yDek7oeEAAAAZQZokSahBbJlMCGf//p4Ya42gMsAAAAMCFgAAABhBnkJFFSwj/w4MBo/AABATHaGBFGcZXekAAAAWAZ5hdEf/EwQ9Tf+hYAAFhx2wCBF6YAAAABQBnmNqR/8TKEn4AABOO7H4ZVG8gQAAABdBmmhJqEFsmUwIZ//+nhAAAAMAAAMDPwAAABhBnoZFFSwj/w4MBo/AABATHaGBFGcZXekAAAATAZ6ldEf/EwRKcAAAnB+0k4xsnQAAABQBnqdqR/8TKEn4AABOO7H4ZVG8gAAAACRBmqxJqEFsmUwIZ//+nhwaCwAE6uxCjhno3QX+BeAAAAMAN6AAAAAbQZ7KRRUsI/8ODANrj+ZZZgAAWwL5zOV5m4IPAAAAFQGe6XRH/xMEQQqFgAAWHG53NUXpgAAAABUBnutqR/8TKEUhULAAAsUvGcHl0PAAAAAaQZrwSahBbJlMCGf//p4dXPd4EwAAAwAAu4EAAAAZQZ8ORRUsI/8ODAP/kiAAAn4joNRK5aZXewAAABMBny10R/8TBEpwAACcH7STjGydAAAAIAGfL2pH/xMoXL8IADXvhREUyfYMyXlAAAYguvnfndDwAAAAF0GbNEmoQWyZTAhn//6eEAAAAwAAAwM+AAAAGEGfUkUVLCP/DgwGj8AAEBMdoYEUZxld6QAAABMBn3F0R/8TBEpwAACcH7STjGycAAAAFAGfc2pH/xMoSfgAAE47sfhlUbyAAAAAJ0GbeEmoQWyZTAhn//6eHU/EycQAmYGUtqzK2X1M0rYJoAAAAwBdwQAAACZBn5ZFFSwj/w4MCxCYYAlyU7ZiT27w//0rmSAAAgvTkCr4It8EHAAAABgBn7V0R/8TBC+YMfT7TAAAtVEPoB/veG8AAAAnAZ+3akf/EyhH4JAHOUcxt4czOO0bRinZsFTUvgAAPMqovbQUN1CBAAAAHEGbvEmoQWyZTAhn//6eHVz3bL8QWbQAAAMAW0AAAAAaQZ/aRRUsI/8ODArzqNeAABBjhfBSLdj3UIEAAAATAZ/5dEf/EwQ59W2AAAdz3eZ6qAAAACMBn/tqR/8TKD3WOooAzJ93FBq0ndolcw3bpbDgAAPMn8S1KwAAABlBm+BJqEFsmUwIZ//+niGvq0At4AAAAwGfAAAAFUGeHkUVLCP/DfDkfgAAfTrIj0bJuAAAABoBnj10R/8TBG/+EAByO7q3t4IsgAA2a7GqoAAAABgBnj9qR/8Rx/gAeoKVasKf7wAATi3kFbEAAAAXQZokSahBbJlMCGf//p4QAAADAAADAz4AAAAiQZ5CRRUsI/8MwOKAIICd+WOq2gayKYDniwAADTOzSSWZNwAAABQBnmF0R/8TMyPwAACYniy4x86bgAAAABQBnmNqR/8TE+bwAADOE9s08efegQAAABdBmmhJqEFsmUwIZ//+nhAAAAMAAAMDPwAAABVBnoZFFSwj/wAAAwABTINFk7efAcEAAAAQAZ6ldEf/AAADAAIKw8XAgQAAABABnqdqR/8AAAMAAgvxvfXAAAAAF0GarEmoQWyZTAhn//6eEAAAAwAAAwM+AAAAJkGeykUVLCP/DMVCAFh7lJyPrRoPTvWlrFkHrusMAAAbAGrqTDJvAAAAFAGe6XRH/xGkCrYAALMNZrjHzpuAAAAAFAGe62pH/xGI1DYAALK0WzTx596AAAAAJ0Ga8EmoQWyZTAhn//6eI1MMAArOnu5F2m0vGBMJd14E7AAAAwAsoQAAABZBnw5FFSwj/w4BKGIAADL1eT2Nm4eRAAAAEAGfLXRH/wAAAwACCsPFwIEAAAARAZ8vakf/EyhJ+AAATDwNsaAAAAAZQZs0SahBbJlMCGf//p4hr6tALeAAAAMBnwAAABVBn1JFFSwj/w3w5H4AAH06yI9GybkAAAAfAZ9xdEf/EwNWgBeLQh/4/zJz0hNd1IRBYAAFY7d4zAAAABgBn3NqR/8RwoGABs9jGKtevvAABOLeQVsAAABDQZt4SahBbJlMCGf//p4jRwq6DQi70AC6sSvULF6NE8U8Ad2luM5q3AJ2AAPIxpov3SBlmdcyaZniZXz1DO/ilEJGBQAAABdBn5ZFFSwj/w3j86dNH4AAH065o8oybgAAABMBn7V0R/8TMyPwAAZ8f3m3pvKhAAAAIAGft2pH/xM33vgCZ973bQVnmHRoiXnWFAAeV+fC2JWdAAAAbUGbvEmoQWyZTAhn//6eUW2nACKuyU8QX0Gw7R9OiBFtiC/yMYFB+Y7CoKIPIg4EBwDCqMYWASKAAAADAAAoN6/21TLFSJhC4GlJEhnMPDWXGDAqayVERz7it2fsWETi3kf/uhUu4gkoVm3B7iAAAAAgQZ/aRRUsI/8TommaHGxAAtur5uhn3Zpv7xPZwAQAj4EAAAAiAZ/5dEf/EwRKbLmAHSJWrR82Zyd8DC42imAD9pyznq3RcAAAABoBn/tqR/8ZadlHaQcaDgAQ3m9zOH0tSKALaQAAAHdBm+BJqEFsmUwIZ//+nlOvfZ8eUkAH/LsNRmMcgfCUs9PB2sLHQQ8eJ6ixctrq6vZWxAbnAxPqoRH1uYAAAAMAAJr2Pns52G8TghSIOnNKtxF7+9tUyxTqFfuOcn7CtGvQlYOAqXcg5DbbZzMlZ0EMDrEpbzJKmQAAAD5Bnh5FFSwj/xNn5oCDAAhn4+AAofg/Tj+2pxGxU2d2ysBfp2jKNTnOMIHSvUgCSf+i2+CJ5V1nrrowT+gE3AAAACsBnj10R/8ZhaXVuPwhMoyfQ5SYA5LJc/DPVMHoJYwAbjsynb5xGRtmALaAAAAAJQGeP2pH/xlnpKLdduRYc80TquzH/2+JGwAAWZolKOyUVfSYZcEAAACCQZokSahBbJlMCF///oz/EFf6DtgAx8l/gtaKfzm6zvdz7XPAWKqvFJ0Qdq1SMlxSH3+FEe24acB8o77B0XWYMu/QAAADAAAVnn/JD8ISdF6zdGsg9ZmfkAns7s/97apljwH3qVDhLnBkEmxSu3o7zBbk7DVn2/3sPMZWqU8o9O8OOAAAAERBnkJFFSwj/xM1OfncB1zAATWIIlQD8cyzeuwOj5VaNIv1rx8+tL+kdgmjOnVta3+AA9L4rBafR0zraX5DF3KzrgAOmQAAAC8BnmF0R/8ZJqPBEwNmXhHRovZEppwBqj/1MblbSq1PDCADtXGPms2d/4xy4YAS8AAAAC4BnmNqR/8ZZ6FMeoB1Ey9rlSzJrVpyJgDqkNjMhLek4J/0bQ5RAD3YKx1csBZRAAAA1kGaaEmoQWyZTAhf//6NPyOpOZMcALePS/ofi/S57lgWt6N7KMyyh5KO7RJJ98qFRyrfmT5nRi+9mtBH91DXMcp1ZRiF7gFRHD/Bi43g4RtNdb8AhPGBJKT7FLb+idW/5sb7eObcQARQYgXRROWx9qRDE+xiLf/zTdcf0OKBpur6HEYx7+VUx1YkaV5c65pQqRAAAAMAAB2CWbCBHUZt7fs5v7axG3A2Bfh1+9921TLC9G0bQguYe+v7+JXBEotkfva6NmrOgjEVCdBsCIytwcuDOfxs77kAAABTQZ6GRRUsI/8WMjvtUTzkQAtSkENeoVrjnhl9Nn/vgDtUQ85ttcFCq/hKJyl8vZNyOaRk4/9LANDAAjM9lr+Z623tQdkCQyOovsXreKLv9YoAKCEAAAA2AZ6ldEf/GYWl4pP6AD4R8fsOUhV8k7datAZGGbMA2Us7bU51QPIAPpXYEOo2Gvd0F3CbiQK3AAAARAGep2pH/xxVrlE2mtz6gV+HAATWvuc5ux1z0/qPn78Y3At2fzil3spxTNBMri4AKQNnMeRyv6h2sj0oWRHjJVy1EBQQAAAA50Gaq0moQWyZTAhf//6NMUFSajJgBs5H5MQSBk+4n2+Q8InLCopwE2qcd86s646WTyZnlmIDYSltHzX7fSsG00vy6EsmJMD+9sscQwJuIna7/o4uDZwGkGiUADDDJBwoV0cs01VzEOJSe+dRHJUx4IZInhJdOAAAAwAEIh9sNzl41nIQ/Z6UqD+r+EGrK6L0wbvkDKqBkHJ4wJHGPe7aplmZXccjSCTrY7SK7pAEIB974Y3G9tCHksj9oZaFcrR/ezYLtfX8y8COLCVK9jhCA41FL4U05xrLms3O/3lEXzorq/pAYnt8aQAAAFRBnslFFSwj/xXXxgC82AgF00e+FHVQAercjk4MI5oQdAdm5OhxN6ZvsVIojXJzEsDchB4wzSNfTQVBgAyMNNNII8y9LW/xlzGone0pszpd7fsABs0AAABlAZ7qakf/HCa6j2TB4ADPADi/Kd9QOYlZ8ekGoME7m21iZNnvVjBdU+52ZrXNFSzo7IZuCKZPnDJFka+z8JLYg+tGH31MAFkRYqgxqrC22p4AJy5kWsaWQY/7aPsmLYILYY5oBvQAAADWQZruSahBbJlMCF///o061cfThHgAV57oZcv61BfU7nAIwRzqS+CLBBsQE1kGy9Bs68vsfO79OuG92vNRFmjra/vvPHAxrRujfN5vyKAdWHwClHcHSls2AfJgm9Y3uAhoktm8AAADAAADAbkCjcBKs23CfYTdY0u1PEbFfhea6Ztsk6992tSqROZO3/en6GsoqHsm19bGtNC06ThSzXNl2li9aHXf4sDCAPmFZzzSaf62N0cf0U8AO5L/q28CBkO5n04PJm+MUb8+/3p4tIHSqm9kBJj0gAAAAGRBnwxFFSwj/xWrM9tKGZq4UgHxCAece29WX0mnIgNbKqz0rc6RjryHw0jfnW8shD7mWZcBD+jwIJegcw5LjS9QOWj4qeAyotsXixI53UqA92yVluk96Ho1oQmWnPJeAbIcAAOnAAAAUAGfLWpH/xyUt2yq+lg4DHWCgBK0BsqSbt8izuJ+eL7ARsmamVw03/IpIG22ypojNp+JwydBB6A/fg77z0BKzaTFAAx2AxMGcBH7AP/V0ZZRAAAA9UGbMUmoQWyZTAhX//45WuD7fWegnQATt533crcJt74Yj0XDAeD4AGYPKDbG8I4w/eDHdTCYvdrWcI/qr6T9GH2VVCawKS0y/kDE3d6GTuJ5sf21RXG4TPmiq7UElRSIvgFa3fS2KFtQ4fNe1VmAAAADAAhGhtDbohcSAj2drDXj/Cvn4UV1HayXj1WJJE3ftUhkCSrwr9Zfpvx6KyqPUQp9cfjuS5Cfvu1qVRoFDcKZDg5CTjiPQz1tZYN8ah2tl+TjukUK6eWsFSfT8Aa31n8wIqqGC/Hca+0f6PfEHYCeYjaD7jre98QYPHlXIgRJAGFa0IrZAAAAWkGfT0UVLCP/FZL7+y2l3QACIUaHWOopaFK7PVmDkRNKUfj7aMbidXfYIwJWixObdwrvzHLTvjvWT0uLRAxx39VicGqAMRmevJcSwqNZQrnBa7kh7aBlpkADjgAAAEIBn3BqR/8b4qCvdL2e8PFzawu4RQwtiVmoZ9e88gYbvDQBapDG7RC5YnEejl1gP2gc4KkETOXBH/F3VZH4tgugAR8AAAD1QZtzSahBbJlMFEwr//45QSwTl/2YALnby+LQsRnoTLzVkXJdrZXTytWev6ntmw4eFo8NBV0yb7f/redgk7/ZQjkGGtwAAAMAAAMA5Hnp6tz/tqnF8CH5BRMfOxiAopx494K7d7f5xtqbyZTvYXnNhyxTQ9tEGx/o3vdtUyzsWhOmRxDj5vp5XFokjPVa5UmDdxi/kE7VarF0q7+9ReOl3MFWX5xodkIVB6F38nd9tBWLLvAKQLCjgJ6Si6vjY9pAXDm8nlOEFJrw4jDoGnYuAxm1PNwN3YuttkSTcQE461jWAEHlM/DAHbrP6820DoP3Y8MgO6EAAABAAZ+Sakf/IG7seh1UEMJVctABaabnZD2w5Embyaw7oqOiDlrs+qdg3EWOQU1XgQ1WoAfDMDLfy6el4+oC3pCZgAAAAJ9Bm5VJ4QpSZTBSwr/+Ok6f8r7LTkdyexeB4TF3AAJWwGUJqkjv4PgtAlYYQzzgAAADAABd4cNvz+bbQHXeaWTEo9z+JaRG00b8ESKmRi7RNLvdtUyya3fyhaImChEKNHBd9KEal7ZpJrCDHRXE4IpQp2g8VagEA3XXGm4Np9iJrWo/s9wywuEaByyqTyetDmSXKWOjDc/MiaLz0MXAwoAAAAA/AZ+0akf/IJMMK0L2oA+AvQQVuYaHTN0J35/GCB3HQqrTi5ozcOo8/WFPR9ykBD12J0/42vXN2zB6CYJFqAEvAAAAa0Gbt0nhDomUwUTCv/45Zon5yTunrdAa4ELEoJNwuFsXUuwv80DIU8AEFdlbYarFYdrLZauVr2GqRyu2+WYr+yDBMWGD8r7AAco8+qys1miGFE17qm4fKH4tEv70QiuqUbTVHA2Db1Q3MOmAAAAAQQGf1mpH/xx5fGLLhQlJpGTwkeomLpCbIWY8bzmcxErZuKcTA4JCnWVmLvt+T8IACFpVXi54PkAOHy7wJDEtQcCBAAAAY0Gb2EnhDyZTAhX//jhAKyX2jvQ41hm1FbxxalXuWUGuoC/r2foARkCXeDngiC2CuGW65j3cn33IW46LQ8vGgJRldYeiJmJUfbyImXkmfey4Y3DDExVbY3SwKKREhvITrhsKXwAAAGxBm/lJ4Q8mUwIV//44QCtDM90DmvRcsz4agBuQWZllxU1Xe1MkJrlMI+apDQZuMpLXPN1JEqiW1LoE0R5wAIQKAdiiPgVW/KFyloM2EmCrpu1Fjuzid6e0dsMRzzKeMWoHaOHFhrF5CdZMBS8AAABsQZoaSeEPJlMCFf/+OEAr9h1tRj62FoOxdoK2fa0ujuXXAK7b13ayh0m9xW3zZCK/5B9wO2nKTynch+jlrlfoyFx1IovfXSn19G8r41hGtZX0PRvZ8MT6q+4gFy/zmGMyJlP6UJP9umcYeSUvAAAAZ0GaPEnhDyZTBRE8K//+OEApN/6UKFzztobHhg+HPGXWLfi3nqO+r6DY5r+IVD0O4TFfGB0xNz8buuw8qk8fdtJn9lyCuwKjC7vewuIkfBr1jku3NEKuKbIEUB3j4aHpoGpclkBED0gAAAA2AZ5bakf/A/OSptObaSKVvmi9q4QTStY5hpix5m6yt1EWp0zfXYEjKroAAaa9WZgSCAxeAN6BAAAAbUGaXUnhDyZTAhX//jhAC96YQNhoewENNT9IhwKAFoi97naqtBi63n8SKHn0jVF1Cr6MQWWms78t7/uq+ssh3HJ2smef5dx12EwC4hMozzO6GmAWL8/wKKBXxskFBpYH3l77kLTO6wTh+ChJml8AAAB5QZp+SeEPJlMCFf/+OEAMPv/SNEoJIFv5KwP4rBrqz5e4ebh98GyFQ6QAcb61lcWS/HI7gDxXOHoh+PHmkCi+8cAXcRnqWx8joamXUKG0/lHXhRzWdYBD36e2OBBju7CVM19gzfRRRskaDOmfRd/gEjTIXMMQ9hQsoAAAAHFBmoBJ4Q8mUwURPCv//jhAC6cn2gsJP+d1S1+YCwbN7AkN/+NBSxz7MTgDqy7IA8KMVcOMzqv25xQyWd5y10DOKo0A7M9SY0RaJBwUqlu71wEht9A2A4DZqgdLp7YBdJTY781vUBbfyN5Na7I7Ns2ZUAAAADIBnr9qR/8Bh/t6o73jocL3atytKfSnAn9nhjqL+PAgpPcAWq9FCW1SHpCKaAcDTOupuQAAAG5BmqFJ4Q8mUwIV//44QASbomq+bHl3N88tIffGABYLZkHS6cUaG1CXoXJdWNyzkIHwRbvnz9HO/EIiYEnHjC+9V0kzIozo+5B3BGDqOoiZM4LIn1o9S+pPb/mZVghHml71Hh9lh9ZJ64zV5wwK2AAAAFZBmsJJ4Q8mUwIV//44QAR7omy8fsK8ogybJb2oq+g8EAaZ7w0KfZ9eRAF1KUvH2T1CjMSaBRbAVjL6dHvmaQitFltLY7j2XkWqbZMhEbdHuYHhPzoLuQAAAFNBmuRJ4Q8mUwURPCv//jhAAbvf+a6ukMaNc5GPNeBQtDzMgAIyRkqtAToeMWu/HuH0/nLjjeXHVfqN8ZwAanvRuMFEgNKn12U8gLldIqbLf/gFbAAAAEEBnwNqR/8AOe/BHCjOVkX9KtJMQPkb6lfGrbFsQAsRKrMCyrk5iTmt59VaE1Uzb/8ty2fptmWyaOT3+9V2nIStgQAAAG5BmwVJ4Q8mUwIV//44QAGvgzyKID9yIqdEMoBAYwVqA9J/MdPRLsvvQ+XrMp7Dxi7JMuyU6XzeZq2Ox7uChweDR0WTFuNW3w+DYQ8HZvdSM34wuuUN+mj+J+aNaCgnhoyX4sKFofd3Wi4fAAAg4QAAAHVBmyZJ4Q8mUwIV//44QAGx3/pbPUrLNKdmYogBa+lJQbXMb21MWgD9sJZl+M6/g8NFk1GVHYbSa1PTy7C3Y3rs7Kzxmgijp0ZVsFjlB9g+HD6YoXDgE6g7xqYO0vT/smYDw0A5Xon+ihC5n+gW+OYBU/FAPSEAAABaQZtHSeEPJlMCFf/+OEAAp/P+wYjgfYGIbeMwYEl2HaczAxVEibkFbMheJgbqcpgCovrWHxf5zCcNqgMA+twnD/yxIp8pp+iB4KIAbkvLBgXXFoo08TqwAALvAAAAikGbaEnhDyZTAhX//jhAAKjyfVz83a2CRKiJuM2wiYHE2HFniHmox1DokS0YD+Pyh2f3siDNFpYY5ymH6LPy21g7PtIKi4FuAVTZKBATRSDGPkkV3nGSyVpRf17gqVZpe86dGdBmA3H9hKrGrl6dR1KKBcXl3ifal0KtOtumFafIJGWk/7Dw6yJlQAAAAGxBm4pJ4Q8mUwURPCv//jhAAKR7W3z3/n8l3slOMufzuz5VQv2FZFlAC0b3D1tVS7IxHz7QnAYK4bC43h2NCkzwspQ8cu7or4i5fu+pW3JqgsGwWADj0Z9YL1WWH9hsYYRxYQVznV3j0zGQBWwAAAA1AZ+pakf/ABWVAt69xB8GYuBDZNqueru2TQkNj+4Qwfw5G17H5TJx01Tzax61d0U1sJE0NSEAAABtQZurSeEPJlMCFf/+OEAAPlv/SNGRcV9cbMDR1k+fYc1xACaj5XJrgdj6p5aDexbyGNEh3BzwMcqzJuFDpE7/ftS6UOdcI2Hqq1VXWWkNAZhqNJ+cp+i2E+7i0g6IR/W6L2M/Ffw+cz/3GZdkfAAAAElBm8xJ4Q8mUwIV//44QAAYdIjl7XDnFgEgPH4mPdO3Rz6hhoA2XE1HTwxY5A0s6InKwlnh+/0nqNVjP+CNw3EQyPFxtkBFFh4QAAAAekGb7UnhDyZTAhX//jhAABid/5sFq7YMAfzMf/+hh9kIfIHgSkj0y3kql/2ObVKr9M4yNURYEEtQXIR6OgoLwGjmd25vleMOPs+P3M8n3LeMhxCraZbAlWlgdo9usXjbI5/3+fhLdRQP2O6/lVpCGkkx9szrAw9e1dStAAAAaUGaD0nhDyZTBRE8J//98QAAOj6bmxwaOtBxT4d3qv8qvvginZmR7e+i6CMP9gLkO8AAud2EHwFWBMwXV6hEV5/T23dWqco3gRC6CL/H9OiTmbXEB3v7DQCZ/bosb5ddabWhDbm7g74eEQAAADkBni5qR/8AAyPtptESUWziWvoT6FVS75L47ywNgAJrXTRP0kpPQMKWDtv9mkuT3ZOIqALjbTZcMqEAAAB8QZoxSeEPJlMFPH/8hAAAi3vYt9565lrYNQFnMmzQA4JrgU/4/F5sgbPuTw537Rqs3MbuESwsnTCoPj2CO/PalWG4/6VE3XQzFRCouGXVtT/SXJKVXqZvurrKA8RYeqL9m7ExOarxrBDQg4mITN9neGoX8ChZK5ACR0oKCAAAACsBnlBqR/8AATWOV3ZmRvYSgOE9lKDUT9w4/BX+RiYiadAAJnnGuDRQkASMAAAAeUGaUknhDyZTAhH//eEAAA2O/vxOVheDZ4piMdFTgxaLyThGhxpMDIgiJZz6E8KeGzEtiOgeMcspX4IgBMh74HGCuFrD3XL/hNa4V6w7GSeBNHHlkLZPH+7PZDWNKcYLINu7wrdWEE1FrI26fji++FR1qghtgsqElYEAAACGQZp0SeEPJlMFETx//IQAADO+iinNPsasfAyXdAEWPEXy+QY2GnO0eOOS5uPbFtKHx+dymYJr9j4mpP0PQ6PMQdjf2VNYiYZD9147duRovt4NrMK1FIAAzRJxAkDKfesV3B21JEbLpAVZoXZ5O4nX06MtLI6OGGGVfIvlSAbmCMnoRDdoK2AAAABbAZ6Takf/AABxM37gZlG0eSimK5kjR9xzYJBTwEjWQO4bZAATjT5RmMpNVLuUg9ppsmaqV9PKjqBlqUw56DPvRHD5SQgsnCPvvbBP+zIuLSmw8knwEhWnvywDegAAAG5BmpVJ4Q8mUwI///yEAAAT/jmHjDUsIcuG6KNvBl+43psAuUCifUyjgEh0KX4chGB8oY8m0cNzuYrhM6O+N+ZntGc2NYvurS1vb2FAiiXQ33tsTh9MwfnIYJ61kPT7iTfS+p0NSEyMYtEF3UUSMQAAAJlBmrZJ4Q8mUwI///yEAAAHki1iXxAKFXSyMEdzw5bgWvuGXb9B/qVSjXup2Irr6K6K3gb79JY5+EtJlm+PGTKZ3jNdg2Yb9DmM+dXZC5H3JOelDS6jD1pLPFht9DSGN2dKmP/dgK/6Einw8a015xEw3QtKk0GTIVUXnWlMroSRdKVkMU8bwd8rBTjVFL+18jZPngLsV3KAdMAAAABcQZrXSeEPJlMCEf/94QAAAwHy3/U9464Mhpom5k7LhhaAxcre/LXJfW/vGW2HtxReE1Tx/onOWBO7naPLGrwG/0/pVCcBr5ue0KSitzXcqVVfU71yXMga9C7BIbUAAABvQZr5SeEPJlMFETx//IQAAAdz0T8+wcsMxENN0NLSE9XhtNi6IQpFvXlmzeCx4sEga0YSx283Tda/SqGU8pb4nPRL2OJNUUcv+DgHzZkAwFUD/jqlR2IUE/qXNuBoS5Z9kX8YTptP216onFMsjSFhAAAASwGfGGpH/wAAEFjld6yE5+j82ggkaAD8SEqHpQYR4HBPQ8utWHicfxRTvAoB1lvBgkD3e4uWsBx+sn+12+iq7wulaKXACVVepDIdUAAAAHtBmxpJ4Q8mUwIV//44QAAAMTv/ShWI5YLL/bES6Jtk9D4jX9l0WtwhlmBMcF/PK49dlOxdKpxcfXlo6ee8Y1Edi/S/8/ig85pq4ZXu+BW9JXmk6uY4O00dM9EYwMIKdOiue8uJia9h+J6E2/Fr93m+766WRjudIFZTBZUAAABnQZs7SeEPJlMCFf/+OEAAABLuia7Ka+DrdFWBv+ogBZthA8ArAbWhmqml/psuC4gFPXOjWhzyQo2Jed3wZ3y5/nfDc9nqVz8HrVNRAsFL18J47+0E42VqLcLZx5fSz7/m1L1bov1R/gAAAGpBm1xJ4Q8mUwIV//44QAAALr7W3z3/oATfNZ1uuAau5feIcGRECyzVJP5AsSBsXfyx4ectvu23PwU/XJxe5zfgk/TKREpsML83ZdFTDnSC6VNo0QTVz6IYgTh6dYzUxiMBY5Q9YTxkehHTAAAAckGbfknhDyZTBRE8K//+OEAAABHvgiK1WNHWGufHGTqJD7x86pSz5TKf05IAJaq5KRiRHebB0QvrY+W3x4y6zmSB40ekhtu1kP1McRe5uBRa9Q/Yg+9bo7i5LZB2+scSkMY3iAjUKIHQeyZV7XFHCfhBwQAAAFUBn51qR/8AAAMCWyPbuLTuFEMMNIvmBYN1XnHOaN43/zMAJjZXvel9atAgHNWdC9gtUSuotVdnatTiNiMyubiVAXWMLGBWYAAAqPn9t3LEpxMPL2LKAAABIUGbgknhDyZTAhH//eEAAAMAGx9j2cepVH1ZuTV6XQMRx+v9gDlwz/R2/q/CtAkic5ycGbQX9g+yZU5NSIWuFit79Uq4qD/v16ANL1aMzHQyS/t9jQrMHqaxGt2ceDuDIx9QG2VAHq7mt6i8H41mz/VvC10E9Z5QrtSJxInGwtKj0P/PR4FHN0hLgl1wLglAx+12xuzX8qv0dpvxs99y9jMuKSp7MZ+cX3hH/Ga4/ZClujfc/tWBjk74XRFbbBV11RU839oZb/qQQzPeUr57eMO67c7oPTePTLnQi5sLasjkZFz56RrM1zRqCCqB4oahTylHHei1Ps4bXKfQ1DLpMmTn0/ZpFFoiAnT4F57lVzv8xasRI4gGMOAQBxVssdZQJGAAAAB4QZ+gRRE8I/8AVV5UFQOG0uY89uRbOb5SMmLAiNP6PVm1XLzJVS/iNVU8qAIeh1zGELc+5OSuqjUweG+/3lNl8LXHfvr93AtsBwUWWizy5STef1keVBMk5LZM0eoyVq4OaSAnGWx4Z9egKW9TbVHclieJjOo9nMCBAAAAOgGf33RH/wAAAwJqw4/vkoWn7LDecR8tcnQG9HnMRwXV6nN4dIscMmqGSYx91HSxsQgQcADf1/pf48AAAACSAZ/Bakf/AAADAmvx01GV1wBRxUFDVnPOTv7onfqP0ikuHwubJh5jP82HOvEQyCJO6fQZcmT1QRiVyoBc4ArI6WMmSnf9BXuGHhDvaJ7YXWb/eenp1rpQE1R9hgGR/yHIdKDADEhe9CZJI+9wY4rRvcGDpHJByPm99DO/7Co+0ib7HfG/BLtZlEVfbSwT9fPmvm8AAAAWQZvDSahBaJlMCP/8hAAAAwAAAwDAgAAAC8Ntb292AAAAbG12aGQAAAAAAAAAAAAAAAAAAAPoAAAPUAABAAABAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACAAAK7XRyYWsAAABcdGtoZAAAAAMAAAAAAAAAAAAAAAEAAAAAAAAPUAAAAAAAAAAAAAAAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAEAAAAACWAAAAZAAAAAAACRlZHRzAAAAHGVsc3QAAAAAAAAAAQAAD1AAAAIAAAEAAAAACmVtZGlhAAAAIG1kaGQAAAAAAAAAAAAAAAAAADIAAADEAFXEAAAAAAAtaGRscgAAAAAAAAAAdmlkZQAAAAAAAAAAAAAAAFZpZGVvSGFuZGxlcgAAAAoQbWluZgAAABR2bWhkAAAAAQAAAAAAAAAAAAAAJGRpbmYAAAAcZHJlZgAAAAAAAAABAAAADHVybCAAAAABAAAJ0HN0YmwAAACYc3RzZAAAAAAAAAABAAAAiGF2YzEAAAAAAAAAAQAAAAAAAAAAAAAAAAAAAAACWAGQAEgAAABIAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAY//8AAAAyYXZjQwFkAB//4QAZZ2QAH6zZQJgz5eEAAAMAAQAAAwBkDxgxlgEABmjr48siwAAAABhzdHRzAAAAAAAAAAEAAADEAAABAAAAABRzdHNzAAAAAAAAAAEAAAABAAAFsGN0dHMAAAAAAAAAtAAAAAEAAAIAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAEAAAAAAIAAAEAAAAAAQAABAAAAAACAAABAAAAAAEAAAQAAAAAAgAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAADAAACAAAAAAEAAAMAAAAAAQAAAQAAAAACAAACAAAAAAEAAAMAAAAAAQAAAQAAAAACAAACAAAAAAEAAAMAAAAAAQAAAQAAAAAEAAACAAAAAAEAAAMAAAAAAQAAAQAAAAADAAACAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAgAAAAABAAADAAAAAAEAAAEAAAAAAwAAAgAAAAABAAADAAAAAAEAAAEAAAAAAwAAAgAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAACAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAxAAAAAEAAAMkc3RzegAAAAAAAAAAAAAAxAAACHwAAADCAAAAQAAAAC4AAAAoAAAAdAAAADIAAAAqAAAALQAAALQAAABSAAAAPwAAADsAAABdAAAAPgAAADoAAAAvAAAAPQAAADYAAAAtAAAAJgAAAFkAAAA/AAAAQgAAADkAAAA3AAAAKgAAACwAAAAqAAAAMAAAACQAAAAdAAAAHAAAACsAAAAqAAAANAAAACcAAABPAAAAKgAAADAAAAAsAAAASwAAACUAAAAdAAAAGwAAAB0AAAAeAAAAJwAAACIAAAAbAAAAHgAAACkAAAAZAAAAGwAAAB4AAAAZAAAAGQAAABsAAAAqAAAAGwAAACcAAAAsAAAAIQAAABcAAAAmAAAAHQAAABwAAAAaAAAAGAAAABsAAAAcAAAAFwAAABgAAAAoAAAAHwAAABkAAAAZAAAAHgAAAB0AAAAXAAAAJAAAABsAAAAcAAAAFwAAABgAAAArAAAAKgAAABwAAAArAAAAIAAAAB4AAAAXAAAAJwAAAB0AAAAZAAAAHgAAABwAAAAbAAAAJgAAABgAAAAYAAAAGwAAABkAAAAUAAAAFAAAABsAAAAqAAAAGAAAABgAAAArAAAAGgAAABQAAAAVAAAAHQAAABkAAAAjAAAAHAAAAEcAAAAbAAAAFwAAACQAAABxAAAAJAAAACYAAAAeAAAAewAAAEIAAAAvAAAAKQAAAIYAAABIAAAAMwAAADIAAADaAAAAVwAAADoAAABIAAAA6wAAAFgAAABpAAAA2gAAAGgAAABUAAAA+QAAAF4AAABGAAAA+QAAAEQAAACjAAAAQwAAAG8AAABFAAAAZwAAAHAAAABwAAAAawAAADoAAABxAAAAfQAAAHUAAAA2AAAAcgAAAFoAAABXAAAARQAAAHIAAAB5AAAAXgAAAI4AAABwAAAAOQAAAHEAAABNAAAAfgAAAG0AAAA9AAAAgAAAAC8AAAB9AAAAigAAAF8AAAByAAAAnQAAAGAAAABzAAAATwAAAH8AAABrAAAAbgAAAHYAAABZAAABJQAAAHwAAAA+AAAAlgAAABoAAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAAAAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRhAAAAAQAAAABMYXZmNTguMjkuMTAw' controls>Sorry, seems like your browser doesn't support HTML5 audio/video</video></div>"
      ],
      "text/plain": [
       "<moviepy.video.io.html_tools.HTML2 object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"save_best\": False,\n",
    "    \"base_dir\": \"${gym_env.env_name}/td3-S${algorithm.seed}_${current_time:}\",\n",
    "    \"collect_stats\": True,\n",
    "    # Set to true to have an insight on the learned policy\n",
    "    # (but slows down the evaluation a lot!)\n",
    "    \"plot_agents\": True,\n",
    "    \"algorithm\": {\n",
    "        \"seed\": 1,\n",
    "        \"max_grad_norm\": 0.5,\n",
    "        \"epsilon\": 0.02,\n",
    "        \"n_envs\": 1, # 1,\n",
    "        \"n_steps\": 100,\n",
    "        \"nb_evals\": 10,\n",
    "        \"discount_factor\": 0.99,\n",
    "        \"buffer_size\": 2e5, #2e5,\n",
    "        \"batch_size\": 64,\n",
    "        \"tau_target\": 0.05,\n",
    "        \"eval_interval\": 2_000,\n",
    "        \"max_epochs\": 2_000,\n",
    "        # Minimum number of transitions before learning starts\n",
    "        \"learning_starts\": 10000,\n",
    "        \"action_noise\": 0.1, #0.1,\n",
    "        \"architecture\": {\n",
    "            \"actor_hidden_size\": [1000, 1500, 1000],#[400, 300],\n",
    "            \"critic_hidden_size\": [1000, 1500, 1000], # [400, 300],\n",
    "        },\n",
    "    },    \n",
    "    \"gym_env\": {\n",
    "        \"env_name\": \"LunarLanderContinuous-v2\",\n",
    "    },\n",
    "    \"actor_optimizer\": {\n",
    "        \"classname\": \"torch.optim.Adam\",\n",
    "        \"lr\": 1e-3,\n",
    "    },\n",
    "    \"critic_optimizer\": {\n",
    "        \"classname\": \"torch.optim.Adam\",\n",
    "        \"lr\": 1e-3,\n",
    "    },\n",
    "}\n",
    "\n",
    "td3 = TD3(OmegaConf.create(params))\n",
    "run_td3(td3)\n",
    "td3.visualize_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a515c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # Do one 10 seed run\n",
    "# seeds = [np.random.randint(0, 1000) for _ in range(10)]\n",
    "# td3s = []\n",
    "# params['base_dir'] += \"_10_runs_10k_epochs2\"\n",
    "# params['algorithm']['max_epochs'] = 10_000\n",
    "# for seed in seeds:\n",
    "#     params[\"algorithm\"][\"seed\"] = seed\n",
    "#     td3 = TD3(OmegaConf.create(params))\n",
    "#     run_td3(td3)\n",
    "#     td3s.append(td3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b6215ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'td3s' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize the best agent\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m td3 \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtd3s\u001b[49m:\n\u001b[0;32m      3\u001b[0m     td3\u001b[38;5;241m.\u001b[39mvisualize_best()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'td3s' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize the best agent\n",
    "for td3 in td3s:\n",
    "    td3.visualize_best()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5b60dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset tensorboard\n",
    "#!kill 23440\n",
    "\n",
    "# Start tensorboard\n",
    "#!tensorboard --logdir outputs/tblogs --port 6006 --bind_all\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_markers": "\"\"\""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
